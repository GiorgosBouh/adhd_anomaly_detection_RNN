import os
import pandas as pd
import numpy as np
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import SimpleRNN, Dense
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.layers import Normalization

# Define the folder path and output file
folder_path = "/Users/user/Documents/εργοθεραπεία_project/anomaly_detection/archive/anomaly_detection_activity"
output_file = "/Users/user/Documents/εργοθεραπεία_project/anomaly_detection/archive/anomaly_detection_activity/anomaly_rnn_results.csv"

# Initialize a results list
results = []


# Define function to preprocess the data
def preprocess_data(data):
    normalization_layer = Normalization(axis=-1)
    activity_data = data[:, 1].astype(float).reshape(-1, 1)  # Convert activity column to float
    anomaly_data = data[:, 2].astype(int)  # Ensure anomaly column is int
    normalization_layer.adapt(activity_data)
    data_scaled = np.hstack([normalization_layer(activity_data).numpy(),  # Scaled activity
                             anomaly_data.reshape(-1, 1)])  # Anomaly column (unchanged)
    X, y = [], []
    for i in range(10, len(data_scaled)):  # Using the past 10 steps for prediction
        X.append(data_scaled[i - 10:i, 0])  # Scaled activity column
        y.append(data_scaled[i, 1])  # Anomaly column
    return np.array(X).reshape(-1, 10, 1), np.array(y)


# Iterate through all files in the folder
for file in os.listdir(folder_path):
    if file.endswith(".csv"):
        file_path = os.path.join(folder_path, file)
        data = pd.read_csv(file_path, delimiter=";", parse_dates=["TIMESTAMP"])

        # Ensure the data has the expected columns
        if data.shape[1] != 3:
            print(f"Skipping file {file}: Unexpected number of columns")
            continue

        # Preprocess data
        X, y = preprocess_data(data.values)

        # Split into train and test sets
        split_index = int(len(X) * 0.8)
        X_train, X_test = X[:split_index], X[split_index:]
        y_train, y_test = y[:split_index], y[split_index:]

        # Build the RNN model
        model = Sequential([
            SimpleRNN(50, activation='relu', input_shape=(10, 1)),
            Dense(1, activation='sigmoid')
        ])
        model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

        # Train the model
        early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)
        model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=20, batch_size=32,
                  callbacks=[early_stopping], verbose=1)

        # Evaluate the model
        loss, accuracy = model.evaluate(X_test, y_test, verbose=0)
        results.append({
            "File": file,
            "Accuracy": accuracy,
            "Loss": loss
        })

# Save the results to a CSV file
results_df = pd.DataFrame(results)
results_df.to_csv(output_file, index=False, sep=';')

print(f"Results saved to {output_file}")

